\section{Related Work}\label{sec:related}
% discusstion
% - model is still quite small. cam we use bigger CNNs?
%% \fixme{What we want to say:
%%   1) We showed DNN is feasible on today's embedded computing
%%   platforms.
%%   2) But, the CNN model is rather smaller-kind with respect to today's
%%   state-of-the-art CNNs, which are much bigger.
%%   3) disscuss google's object detection api
%%   paper~\cite{huang2017speed}. 
%%   4) Applying these much more complex DNNs (such as google's detection
%%   models) may be challenging for embedded computing
%%   platforms.
%%   5) Two general approaches: (1) make it faster (computing workload
%%   remains the same) (2) reduce the workload itself (model compression
%%   or reduced precision etc.)}

%% {\bf DNN optimization for embedded systems.}

There are several relatively inexpensive RC-car based autonomous car
testbeds. MIT's RaceCar~\cite{shin2017project} and UPenn's
F1$/$10~\cite{upennf1tenth} are both based on a Traxxas 1/10 scale RC
car and a NVIDIA Jetson multicore computing platform, which
is equipped with many sophisticated sensor packages, such as a lidar.
However, they both cost more than \$3,000, requiring a considerable
investment. DonkeyCar~\cite{donkeycar} is similar to our DeepPicar as
it also uses a Raspberry Pi 3 and a similar CNN for end-to-end
control, although it costs more (about \$200).
%% because it uses a more
%% expensive 1/16 scale RC car than our 1/24 scale one.
The main contribution of our paper is in the detailed analysis of
computational aspects of executing a CNN-based real-time control
workload on diverse embedded computing platforms.

In this paper, we have analyzed real-time performance of a real-world
CNN, which was used in NVIDIA's DAVE-2 self-driving
car~\cite{Bojarski2016}, on a low-cost raspberry pi 3 quad-core 
platform and other embedded multicore platforms. It should be noted, 
however, that DAVE-2's CNN is relatively small compared
to recent state-of-the-art CNNs, which are increasingly larger and
deeper. For example, the CNN based object detector models evaluated in
Google's recent study~\cite{huang2017speed} have between 3M to 54M
parameters, and are much larger than DAVE-2's CNN.
Using such large CNN models will be challenging on
resource constrainted embedded computing platforms, especially for
real-time applications such as self-driving cars.

%% available DNN's can be much larger compared to the architecture of the
%% DAVE-2. Such DNN's can be seen in Google's Object Detection API
%% The smallest model available in the API is the MobileNet model, which
%% has 3,191,072 parameters and is approximately 12.7 larger than the
%% model used by the DeepPicar. The other models all have parameter sizes 
%% of at least 10 million. Due to the considerable differences in the 
%% model sizes, it is likely that running them on platforms like the Pi 3,
%% and still get acceptable real-time performance would be difficult, 
%% if not infeasible. 

%% % related work on efficient DNN representation and processing.
%% While repeated feedforward and backpropagation operations during
%% the training time account for most of the computational cost in
%% deep learning, there is a growing need for an improved efficiency
%% during the inferencing time as well, especially because of the
%% potential of utilizing Deep Neural Networks (DNN) for the real-time
%% pattern recognition tasks in embedded systems, as our paper
%% exemplifies.

While continuing performance improvements in embedded computing
platforms will certainly make processing these complex CNNs faster,
another actively investigated approach is to reduce the required
computational complexity itself.
%% When a DNN is deployed in those implementations with limited
%% resources, such as memory and power, the floating-point operations
%% involved in the large matrix multiplications are a burdensome task.
Many recent advances in network compression have shown promising results
in reducing such computational costs during the feedforward
process. The fundamental assumption in those techniques is that the
CNNs are redundant in their structure and representation. For example,
network pruning can thin out the network and provides a more condensed
topology~\cite{han2015deep}.

Another common compression method is to reduce the
quantization level of the network parameters, so that arithmetic
defined with floating-point operations are replaced with low-bit
fixed-point counterparts. To this end, single bit quantization of the
network parameters or ternary quantization have been recently proposed
~\cite{hwang2014fixed,soudry2014expectation,kim2016bitwise,rastegari2016xnor,hubara2016binarized,beauchamp2006embedded,govindu2004analysis}.
In those networks, the inner product between the
originally real-valued parameter vectors is defined with XNOR followed
by bit counting, so that the network can greatly minimize the
computational cost in the hardware implementations. This drastic
quantization can produce some additional performance loss, but those
new binarized or ternarized systems provide a simple quantization
noise injection mechanism during training so that the additional error
is minimized to an acceptable level.

The XNOR operation and bit counting have been known to be efficient in
hardware implementations. In~\cite{rastegari2016xnor}, it was shown
that the binarized convolution could substitute the expensive
convolutional feedforward operations in a regular Convolutional Neural
Network (CNN), %% by using only about 1.5\% of the memory space, while
providing 20 to 60 times faster feedforward. Binary weights were also
able to provide 7 times faster feedforward than a floating-point
network for the hand written digit recognition task as well as 23
times faster matrix multiplication tasks on a
GPU~\cite{hubara2016binarized}.
Moreover, FPGA implementations showed that the XNOR operation is 200
times cheaper than floating-point multiplications with 
single precision~\cite{beauchamp2006embedded,govindu2004analysis}.
XNOR-POP is another hardware implementation that reduced
the energy consumption of a CNN by 98.7\%~\cite{jiang2017xnor}.

These research efforts are expected to make complex CNNs more
accessible for a wider range of real-time embedded systems. We plan to
investigate the feasibility of these approaches in the context of
DeepPicar so that we can use even more resource constrained
micro-controller class computing platforms.

%% % related work on testbeds
%% \fixme{maybe we can also discuss MIT racecar, UPENN car, donkey car and other testbeds?
%%   The points of discussion may include: 1) they are expensive. 2)
%%   donkey car is similar to us, but still a bit more expnsive, and more
%%   importantly there is no existing studies which systematically evaluate
%%   real-time performance of using DNN on embedded computing
%%   platforms. Our work provides quantitive real-time performance
%%   evaluation results, using a known DNN used in a real self-driving
%%   car. Our work is fully reproducible at a very low cost, lowring the
%%   barrier to entry in researching self-driving cars, helping the
%%   community blah blah blah.}
  

%% and the ability of the car to navigate the desired environment. We are 
%% more focused on the real-time performance of the DeepPicar, and whether
%% the Raspberry Pi 3 embedded computing platform can properly support autonomous 
%% vehicle operations. To the best of our knowledge, no other studies have
%% been done to evaluate the capabilities of the Pi 3 for running DNNs and
%% performing autonomous vehicle operations.
